{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254dc7ff-2d6b-415e-962d-51a7c3b17674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grep: warning: GREP_OPTIONS is deprecated; please use an alias or script\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cfba83-e19a-4372-8726-cc75ab784647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.jit import to_static\n",
    "from paddle.static import InputSpec\n",
    "paddle.set_device('cpu')\n",
    "\n",
    "################## 模型组网 ##################\n",
    "x_spec = [InputSpec([None, 4],dtype='float32')]\n",
    "class Net(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = paddle.nn.Linear(4, 4)\n",
    "        self.fc2 = paddle.nn.Linear(4, 4)\n",
    "        self.bias = 0.4\n",
    "        self.flag = paddle.ones([2],dtype=\"int32\")\n",
    "    ################## 导出函数 ① ##################\n",
    "    @to_static(input_spec=x_spec)\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = paddle.nn.functional.relu(out)\n",
    "        out = paddle.mean(out)\n",
    "        return out\n",
    "    ################## 导出函数 ② ##################\n",
    "    @to_static(input_spec=x_spec)\n",
    "    def infer(self, input):\n",
    "        out = self.fc2(input)\n",
    "        out = out + self.bias\n",
    "        out = paddle.mean(out)\n",
    "        return out\n",
    "    ################## 导出变量 ① ##################\n",
    "    # For extra Python float\n",
    "    # @to_static(property=True)\n",
    "    def bias(self):\n",
    "        return self.bias + 1\n",
    "    ################## 导出变量 ② ##################\n",
    "    # For extra Tensor\n",
    "    # @to_static(property=True)\n",
    "    def flag(self):\n",
    "        return self.flag\n",
    "    \n",
    "################## 模型导出 ##################\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e337f54-4b25-4183-a132-24da5d8b9f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__call__ <class 'method'>\n",
      "__class__ <class 'type'>\n",
      "__delattr__ <class 'method'>\n",
      "__dict__ <class 'dict'>\n",
      "__dir__ <class 'method'>\n",
      "__doc__ <class 'NoneType'>\n",
      "__eq__ <class 'method-wrapper'>\n",
      "__format__ <class 'builtin_function_or_method'>\n",
      "__ge__ <class 'method-wrapper'>\n",
      "__getattr__ <class 'method'>\n",
      "__getattribute__ <class 'method-wrapper'>\n",
      "__getstate__ <class 'method'>\n",
      "__gt__ <class 'method-wrapper'>\n",
      "__hash__ <class 'method-wrapper'>\n",
      "__init__ <class 'method'>\n",
      "__init_subclass__ <class 'builtin_function_or_method'>\n",
      "__le__ <class 'method-wrapper'>\n",
      "__lt__ <class 'method-wrapper'>\n",
      "__module__ <class 'str'>\n",
      "__ne__ <class 'method-wrapper'>\n",
      "__new__ <class 'builtin_function_or_method'>\n",
      "__reduce__ <class 'builtin_function_or_method'>\n",
      "__reduce_ex__ <class 'builtin_function_or_method'>\n",
      "__repr__ <class 'method'>\n",
      "__setattr__ <class 'method'>\n",
      "__setstate__ <class 'method'>\n",
      "__sizeof__ <class 'builtin_function_or_method'>\n",
      "__str__ <class 'method-wrapper'>\n",
      "__subclasshook__ <class 'builtin_function_or_method'>\n",
      "__weakref__ <class 'NoneType'>\n",
      "_apply <class 'method'>\n",
      "_buffers <class 'collections.OrderedDict'>\n",
      "_build_once <class 'method'>\n",
      "_built <class 'bool'>\n",
      "_casted_by_pure_fp16 <class 'bool'>\n",
      "_customized_attrs <class 'dict'>\n",
      "_dtype <class 'str'>\n",
      "_dygraph_call_func <class 'method'>\n",
      "_forward_post_hooks <class 'collections.OrderedDict'>\n",
      "_forward_pre_hooks <class 'collections.OrderedDict'>\n",
      "_full_name <class 'str'>\n",
      "_helper <class 'paddle.fluid.dygraph.layer_object_helper.LayerObjectHelper'>\n",
      "_init_in_dynamic_mode <class 'bool'>\n",
      "_loaddict_holder <class 'collections.OrderedDict'>\n",
      "_non_persistable_buffer_names_set <class 'set'>\n",
      "_obtain_parameters_buffers <class 'method'>\n",
      "_op_recorder <class 'paddle.fluid.dygraph.layer_hooks.LayerOpsRecoder'>\n",
      "_original_funcs <class 'collections.OrderedDict'>\n",
      "_parameters <class 'collections.OrderedDict'>\n",
      "_set_op_attrs <class 'method'>\n",
      "_state_dict_hooks <class 'collections.OrderedDict'>\n",
      "_state_dict_impl <class 'method'>\n",
      "_sub_layers <class 'collections.OrderedDict'>\n",
      "_to_impl <class 'method'>\n",
      "add_parameter <class 'method'>\n",
      "add_sublayer <class 'method'>\n",
      "apply <class 'method'>\n",
      "backward <class 'method'>\n",
      "bias <class 'float'>\n",
      "bias <class 'float'>\n",
      "buffers <class 'method'>\n",
      "children <class 'method'>\n",
      "clear_gradients <class 'method'>\n",
      "create_parameter <class 'method'>\n",
      "create_tensor <class 'method'>\n",
      "create_variable <class 'method'>\n",
      "eval <class 'method'>\n",
      "extra_repr <class 'method'>\n",
      "fc1 <class 'paddle.nn.layer.common.Linear'>\n",
      "fc2 <class 'paddle.nn.layer.common.Linear'>\n",
      "flag <class 'method'>\n",
      "flag <class 'method'>\n",
      "forward <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "full_name <class 'method'>\n",
      "infer <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "load_dict <class 'method'>\n",
      "named_buffers <class 'method'>\n",
      "named_children <class 'method'>\n",
      "named_parameters <class 'method'>\n",
      "named_sublayers <class 'method'>\n",
      "parameters <class 'method'>\n",
      "register_buffer <class 'method'>\n",
      "register_forward_post_hook <class 'method'>\n",
      "register_forward_pre_hook <class 'method'>\n",
      "register_state_dict_hook <class 'method'>\n",
      "set_dict <class 'method'>\n",
      "set_state_dict <class 'method'>\n",
      "state_dict <class 'method'>\n",
      "sublayers <class 'method'>\n",
      "to <class 'method'>\n",
      "to_static_state_dict <class 'method'>\n",
      "train <class 'method'>\n",
      "training <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "# getattr will trick decarator\n",
    "for i in dir(net):\n",
    "    print(i, type(getattr(net, i, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55cd286b-d19c-4cec-911e-985a49ff620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['flag', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "d = net.to_static_state_dict()\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "795e7a55-13d2-4a8b-8860-9554893b73ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_kids',\n",
       " '_remove_from_pool',\n",
       " 'drop_kids',\n",
       " 'erase',\n",
       " 'find_var',\n",
       " 'new_scope',\n",
       " 'size',\n",
       " 'var']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = paddle.fluid.core.Scope()\n",
    "dir(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aae8b7e-2f7a-44b9-b456-a5ce14cdaaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "find_var(self: paddle.fluid.core_avx._Scope, name: str) -> paddle.fluid.core_avx.Variable\n",
       "\n",
       "\n",
       "Find variable named :code:`name` in the current scope or\n",
       "its parent scope. Return None if not found. \n",
       "\n",
       "Args:\n",
       "    name (str): the variable name.\n",
       "\n",
       "Returns:\n",
       "    out (core.Variable|None): the found variable or None.\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.find_var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106989ad-1d64-466b-af0e-d296bd732f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "var(self: paddle.fluid.core_avx._Scope, name: str) -> paddle.fluid.core_avx.Variable\n",
       "\n",
       "\n",
       "Find or create variable named :code:`name` in the current scope.\n",
       "\n",
       "If the variable named :code:`name` does not exist in the\n",
       "current scope, the variable would be created. Otherwise,\n",
       "return the existing variable.\n",
       "\n",
       "Args:\n",
       "    name (str): the variable name.\n",
       "\n",
       "Returns:\n",
       "    out (core.Variable): the found or created variable.\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "936a8b2e-7a93-43e4-a822-c9632b970c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m size(self: paddle.fluid.core_avx._Scope) -> int\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29350f5b-1147-468b-b875-072a9dc17f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{var mean_0.tmp_0 : LOD_TENSOR.shape(1,).dtype(float32).stop_gradient(False), var linear_2.tmp_1 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), persist trainable param linear_0.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), var relu_0.tmp_0 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), persist trainable param linear_0.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False), var x : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), persist trainable param linear_1.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), var linear_3.tmp_0 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), persist var generated_tensor_0 : LOD_TENSOR.shape(2,).dtype(int32).stop_gradient(True), var x : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), var tmp_0 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), var mean_1.tmp_0 : LOD_TENSOR.shape(1,).dtype(float32).stop_gradient(False), var linear_2.tmp_0 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), var linear_3.tmp_1 : LOD_TENSOR.shape(-1, 4).dtype(float32).stop_gradient(False), persist trainable param linear_1.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False), persist var generated_tensor_0 : LOD_TENSOR.shape(2,).dtype(int32).stop_gradient(True)}\n",
      "[persist trainable param linear_0.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), persist trainable param linear_0.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False), persist trainable param linear_1.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), persist var generated_tensor_0 : LOD_TENSOR.shape(2,).dtype(int32).stop_gradient(True), persist trainable param linear_1.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False), persist var generated_tensor_0 : LOD_TENSOR.shape(2,).dtype(int32).stop_gradient(True)]\n",
      "[persist trainable param linear_0.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), persist trainable param linear_0.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False), persist trainable param linear_1.w_0 : LOD_TENSOR.shape(4, 4).dtype(float32).stop_gradient(False), persist trainable param linear_1.b_0 : LOD_TENSOR.shape(4,).dtype(float32).stop_gradient(False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/paddle/fluid/io.py:1444: UserWarning: save_inference_model specified the param `program_only` to True, It will not save params of Program.\n",
      "  \"save_inference_model specified the param `program_only` to True, It will not save params of Program.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set \"use_combine=True\" to save for Layer\n",
    "# export.xxx, export.infer.xxx\n",
    "# export.extra -- for all attribute\n",
    "#   - {'bias': self.bias, 'flag': self.flag}\n",
    "paddle.jit.save(net, path=\"./export\", use_combine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d065eb-d413-4216-9e3d-b41a3f0256fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The additional config (use_combine) of `paddle.jit.load` is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25973/1556566712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m################## 模型ji加载 ##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# set \"use_combine=True\" to load as jit::Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./export\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_combine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m################## 函数前后端灵活调用 ##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         assert in_dygraph_mode(\n\u001b[1;32m    228\u001b[0m         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/jit.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, **configs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \"\"\"\n\u001b[1;32m   1122\u001b[0m     \u001b[0;31m# 1. construct correct config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_load_path_and_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/DeepSpeech-2.x/tools/venv/lib/python3.7/site-packages/paddle/fluid/dygraph/jit.py\u001b[0m in \u001b[0;36m_parse_load_config\u001b[0;34m(configs)\u001b[0m\n\u001b[1;32m    393\u001b[0m             raise ValueError(\n\u001b[1;32m    394\u001b[0m                 \u001b[0;34m\"The additional config (%s) of `paddle.jit.load` is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 % (key))\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;31m# construct inner config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The additional config (use_combine) of `paddle.jit.load` is not supported."
     ]
    }
   ],
   "source": [
    "################## 模型ji加载 ##################\n",
    "# set \"use_combine=True\" to load as jit::Layer\n",
    "new_net = paddle.jit.load(path=\"./export\", use_combine=True)\n",
    "################## 函数前后端灵活调用 ##################\n",
    "x = paddle.randn([2,4])\n",
    "# C++端： jit::Layer.Forward(x)\n",
    "out = new_net(x)\n",
    "# C++端： jit::Layer.GetMethod(\"infer\")(x)\n",
    "pred = new_net.infer(x)\n",
    "################## 变量前后端灵活访问 ##################\n",
    "# C++端： jit::Layer.GetAttribute(\"bias\")\n",
    "bias = new_net.bias()\n",
    "# C++端： jit::Layer.GetAttribute(\"flags\")\n",
    "flag = new_net.flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8e4b5b-1fad-4159-b50d-cf7201dbe633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "<function Net.forward at 0x7fc23e7d2d08>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(self, x)\n",
      "False\n",
      "not False <function Net.forward at 0x7fc23e7d2d08>\n",
      "<function Net.infer at 0x7fc23e7c96a8>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(self, input)\n",
      "False\n",
      "not False <function Net.infer at 0x7fc23e7c96a8>\n",
      "<function Net.log_softmax at 0x7fc23e7bc048>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(self, input)\n",
      "False\n",
      "not False <function Net.log_softmax at 0x7fc23e7bc048>\n",
      "<function Net.fbias at 0x7fc23e7bc950>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(self)\n",
      "False\n",
      "not False <function Net.fbias at 0x7fc23e7bc950>\n",
      "<function Net.fflag at 0x7fc23e7bd2f0>\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(self)\n",
      "False\n",
      "not False <function Net.fflag at 0x7fc23e7bd2f0>\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.jit import to_static\n",
    "from paddle.static import InputSpec\n",
    "paddle.set_device('cpu')\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "def wrapper(method):\n",
    "    print(dir(method))\n",
    "    def _impl(self, *method_args, **method_kwargs):\n",
    "        method._origin = method\n",
    "        method_output = method(self, *method_args, **method_kwargs)\n",
    "        return method_output + \"!\"\n",
    "    return _impl\n",
    "\n",
    "   \n",
    "################## 模型组网 ##################\n",
    "x_spec = [InputSpec([None, 4],dtype='float32')]\n",
    "class Net(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = paddle.nn.Linear(4, 4)\n",
    "        self.fc2 = paddle.nn.Linear(4, 4)\n",
    "        self.bias = 0.4\n",
    "        self.flag = paddle.ones([2],dtype=\"int32\")\n",
    "    \n",
    "    def test(self):\n",
    "        return 'a'\n",
    "    \n",
    "    @wrapper\n",
    "    def bar(self, word):\n",
    "        return word\n",
    "    \n",
    "    ################## 导出函数 ① ##################\n",
    "    @to_static(input_spec=x_spec)\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = paddle.nn.functional.relu(out)\n",
    "        out = paddle.mean(out)\n",
    "        return out\n",
    "    ################## 导出函数 ② ##################\n",
    "    @to_static(input_spec=x_spec)\n",
    "    def infer(self, input):\n",
    "        out = self.fc2(input)\n",
    "        out = out + self.bias\n",
    "        out = paddle.mean(out)\n",
    "        return out\n",
    "    \n",
    "    @to_static(input_spec=x_spec)\n",
    "    def log_softmax(self, input):\n",
    "        return paddle.nn.functional.log_softmax(input, axis=-1)\n",
    "    \n",
    "    ################## 导出变量 ① ##################\n",
    "    # For extra Python float\n",
    "    @to_static(property=True)\n",
    "    def fbias(self):\n",
    "        return self.bias + 1\n",
    "    ################## 导出变量 ② ##################\n",
    "    # For extra Tensor\n",
    "    @to_static(property=True)\n",
    "    def fflag(self):\n",
    "        return self.flag\n",
    "    \n",
    "################## 模型导出 ##################\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f031ba97-0624-4fd7-9e68-787e3813674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not False <function Net.flag at 0x7fc23e937e18>\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.ismethod(net.flag))\n",
    "print(inspect.ismethod(net.test))\n",
    "print(inspect.ismethod(net.bar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af6ed3da-6ab7-4401-bfbb-77886c60df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method wrapper.<locals>._impl of Net(\n",
      "  (fc1): Linear(in_features=4, out_features=4, dtype=float32)\n",
      "  (fc2): Linear(in_features=4, out_features=4, dtype=float32)\n",
      ")>\n",
      "<paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction object at 0x7f0adfa576a0>\n",
      "<function Net.flag at 0x7f0adf9b0158>\n",
      "False\n",
      "(self)\n"
     ]
    }
   ],
   "source": [
    "print(net.bar)\n",
    "print(net.flag)\n",
    "print(net.flag._dygraph_function)\n",
    "print(inspect.ismethod(net.flag._dygraph_function))\n",
    "print(inspect.signature(net.flag._dygraph_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49a677a-7301-49f9-90db-70ec723e2ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def a():\n",
    "    return 1\n",
    "\n",
    "print(inspect.ismethod(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad77ecf-a0d2-444f-9202-efaeeea4df55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__call__', <method-wrapper '__call__' of method object at 0x7f0adfc23248>),\n",
       " ('__class__', method),\n",
       " ('__delattr__',\n",
       "  <method-wrapper '__delattr__' of method object at 0x7f0adfc23248>),\n",
       " ('__dir__', <function method.__dir__()>),\n",
       " ('__doc__', None),\n",
       " ('__eq__', <method-wrapper '__eq__' of method object at 0x7f0adfc23248>),\n",
       " ('__format__', <function method.__format__(format_spec, /)>),\n",
       " ('__func__', <function __main__.Net.flag(self)>),\n",
       " ('__ge__', <method-wrapper '__ge__' of method object at 0x7f0adfc23248>),\n",
       " ('__get__', <method-wrapper '__get__' of method object at 0x7f0adfc23248>),\n",
       " ('__getattribute__',\n",
       "  <method-wrapper '__getattribute__' of method object at 0x7f0adfc23248>),\n",
       " ('__gt__', <method-wrapper '__gt__' of method object at 0x7f0adfc23248>),\n",
       " ('__hash__', <method-wrapper '__hash__' of method object at 0x7f0adfc23248>),\n",
       " ('__init__', <method-wrapper '__init__' of method object at 0x7f0adfc23248>),\n",
       " ('__init_subclass__', <function method.__init_subclass__>),\n",
       " ('__le__', <method-wrapper '__le__' of method object at 0x7f0adfc23248>),\n",
       " ('__lt__', <method-wrapper '__lt__' of method object at 0x7f0adfc23248>),\n",
       " ('__ne__', <method-wrapper '__ne__' of method object at 0x7f0adfc23248>),\n",
       " ('__new__', <function method.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <function method.__reduce__>),\n",
       " ('__reduce_ex__', <function method.__reduce_ex__(protocol, /)>),\n",
       " ('__repr__', <method-wrapper '__repr__' of method object at 0x7f0adfc23248>),\n",
       " ('__self__',\n",
       "  Net(\n",
       "    (fc1): Linear(in_features=4, out_features=4, dtype=float32)\n",
       "    (fc2): Linear(in_features=4, out_features=4, dtype=float32)\n",
       "  )),\n",
       " ('__setattr__',\n",
       "  <method-wrapper '__setattr__' of method object at 0x7f0adfc23248>),\n",
       " ('__sizeof__', <function method.__sizeof__()>),\n",
       " ('__str__', <method-wrapper '__str__' of method object at 0x7f0adfc23248>),\n",
       " ('__subclasshook__', <function method.__subclasshook__>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmembers(net.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43428b61-cae6-4c23-89e6-93e2753b753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbias <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "{'build_strategy': <paddle.fluid.core_avx.ParallelExecutor.BuildStrategy object at 0x7fc23e934a40>, 'property': True}\n",
      "{'build_strategy': <paddle.fluid.core_avx.ParallelExecutor.BuildStrategy object at 0x7fc23e934a40>, 'property': True}\n",
      "True\n",
      "flag <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "{'build_strategy': <paddle.fluid.core_avx.ParallelExecutor.BuildStrategy object at 0x7fc23e934b90>, 'property': True}\n",
      "flag <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "{'build_strategy': <paddle.fluid.core_avx.ParallelExecutor.BuildStrategy object at 0x7fc23e934b90>, 'property': True}\n",
      "infer <class 'paddle.fluid.dygraph.dygraph_to_static.program_translator.StaticFunction'>\n",
      "{'build_strategy': <paddle.fluid.core_avx.ParallelExecutor.BuildStrategy object at 0x7fc23e934928>, 'property': False}\n"
     ]
    }
   ],
   "source": [
    "# getattr will trick decarator\n",
    "for i in dir(net):\n",
    "    if i == 'fbias':\n",
    "        print(i, type(getattr(net, i, None)))\n",
    "        a = getattr(net, i)\n",
    "        print(a._kwargs)\n",
    "        print(net.fbias._kwargs)\n",
    "        print(net.fbias.is_property)\n",
    "\n",
    "    if i == 'flag':\n",
    "        print(i, type(getattr(net, i, None)))\n",
    "        a = getattr(net, i)\n",
    "        print(a._kwargs)\n",
    "        \n",
    "    if i == 'infer':\n",
    "        print(i, type(getattr(net, i, None)))\n",
    "        a = getattr(net, i)\n",
    "        print(a._kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d481f3a5-d622-488e-adbf-b0251dc72811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not False <function Net.fbias at 0x7fc23e7bc950>\n",
      "not False <function Net.fflag at 0x7fc23e7bd2f0>\n",
      "not False <function Net.forward at 0x7fc23e7d2d08>\n",
      "not False <function Net.infer at 0x7fc23e7c96a8>\n",
      "not False <function Net.log_softmax at 0x7fc23e7bc048>\n"
     ]
    }
   ],
   "source": [
    "paddle.jit.save(net, path=\"./export_p\", use_combine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b244fa7-1b05-4f43-9d95-99bc83893ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
